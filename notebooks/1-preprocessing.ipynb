{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/adese/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/adese/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/adese/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>rating</th>\n",
       "      <th>text</th>\n",
       "      <th>00</th>\n",
       "      <th>000</th>\n",
       "      <th>000ft</th>\n",
       "      <th>001</th>\n",
       "      <th>0010</th>\n",
       "      <th>0011</th>\n",
       "      <th>0025</th>\n",
       "      <th>...</th>\n",
       "      <th>천하의</th>\n",
       "      <th>첫째</th>\n",
       "      <th>태초에</th>\n",
       "      <th>하나님의</th>\n",
       "      <th>하나님이</th>\n",
       "      <th>하늘이라</th>\n",
       "      <th>하시고</th>\n",
       "      <th>하시니</th>\n",
       "      <th>혼돈하고</th>\n",
       "      <th>흑암이</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>review</td>\n",
       "      <td>3.0</td>\n",
       "      <td>We used this airline to go from Singapore to L...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>review</td>\n",
       "      <td>5.0</td>\n",
       "      <td>The service on Singapore Airlines Suites Class...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>review</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Booked, paid and received email confirmation f...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>review</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Best airline in the world, seats, food, servic...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>review</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Premium Economy Seating on Singapore Airlines ...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 19452 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     type  rating                                               text   00  \\\n",
       "0  review     3.0  We used this airline to go from Singapore to L...  0.0   \n",
       "1  review     5.0  The service on Singapore Airlines Suites Class...  0.0   \n",
       "2  review     1.0  Booked, paid and received email confirmation f...  0.0   \n",
       "3  review     5.0  Best airline in the world, seats, food, servic...  0.0   \n",
       "4  review     2.0  Premium Economy Seating on Singapore Airlines ...  0.0   \n",
       "\n",
       "   000  000ft  001  0010  0011  0025  ...  천하의   첫째  태초에  하나님의  하나님이  하늘이라  \\\n",
       "0  0.0    0.0  0.0   0.0   0.0   0.0  ...  0.0  0.0  0.0   0.0   0.0   0.0   \n",
       "1  0.0    0.0  0.0   0.0   0.0   0.0  ...  0.0  0.0  0.0   0.0   0.0   0.0   \n",
       "2  0.0    0.0  0.0   0.0   0.0   0.0  ...  0.0  0.0  0.0   0.0   0.0   0.0   \n",
       "3  0.0    0.0  0.0   0.0   0.0   0.0  ...  0.0  0.0  0.0   0.0   0.0   0.0   \n",
       "4  0.0    0.0  0.0   0.0   0.0   0.0  ...  0.0  0.0  0.0   0.0   0.0   0.0   \n",
       "\n",
       "   하시고  하시니  혼돈하고  흑암이  \n",
       "0  0.0  0.0   0.0  0.0  \n",
       "1  0.0  0.0   0.0  0.0  \n",
       "2  0.0  0.0   0.0  0.0  \n",
       "3  0.0  0.0   0.0  0.0  \n",
       "4  0.0  0.0   0.0  0.0  \n",
       "\n",
       "[5 rows x 19452 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from langdetect import detect  # For language detection\n",
    "\n",
    "# Downloading NLTK resources\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Loading the CSV data into a DataFrame\n",
    "data = pd.read_csv('singapore_airlines_reviews.csv')  # Replace 'your_data.csv' with the path to your CSV file\n",
    "\n",
    "# Function to detect and filter out non-English text\n",
    "def filter_non_english(text):\n",
    "    try:\n",
    "        if detect(text) == 'en':\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Filtering non-English text\n",
    "data = data[data['text'].apply(filter_non_english)]\n",
    "\n",
    "# Renaming the columns to English\n",
    "data = data.rename(columns={'type': 'type', 'rating': 'rating', 'text': 'text'})\n",
    "\n",
    "# Tokenization (to exclude non-English words)\n",
    "data['tokens'] = data['text'].apply(lambda x: [word for word in word_tokenize(x.lower()) if word.isalpha()])\n",
    "\n",
    "# Removing stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "data['tokens'] = data['tokens'].apply(lambda x: [word for word in x if word not in stop_words])\n",
    "\n",
    "# Lemmatization process\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "data['tokens'] = data['tokens'].apply(lambda x: [lemmatizer.lemmatize(word) for word in x])\n",
    "\n",
    "# Text representation using Bag-of-Words\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(data['text'])\n",
    "text_representation = pd.DataFrame(X.toarray(), columns=vectorizer.get_feature_names_out())\n",
    "\n",
    "# Selecting only the desired columns from the original DataFrame\n",
    "data_selected_columns = data[['type', 'rating', 'text']]\n",
    "\n",
    "data_with_representation = pd.concat([data_selected_columns, text_representation], axis=1)\n",
    "\n",
    "# Displaying the DataFrame with tokenization and text representation\n",
    "data_with_representation.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "firstEnv",
   "language": "python",
   "name": "firstenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
